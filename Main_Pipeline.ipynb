{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Databricks Data Engineering 101: Medallion Architecture\n",
        "\n",
        "**Build Production-Ready Data Pipelines with Bronze, Silver & Gold Layers**\n",
        "\n",
        "Welcome to the core of data engineering on Databricks! In this notebook, you'll learn to:\n",
        "\n",
        "- ü•â **Bronze Layer**: Ingest raw data with complete history\n",
        "- ü•à **Silver Layer**: Clean, validate, and standardize data\n",
        "- ü•á **Gold Layer**: Create business-ready analytics tables\n",
        "\n",
        "## What is Medallion Architecture?\n",
        "\n",
        "The Medallion Architecture organizes data into three progressive layers:\n",
        "\n",
        "```\n",
        "Raw Data ‚Üí [Bronze] ‚Üí [Silver] ‚Üí [Gold] ‚Üí Business Insights\n",
        "           Raw         Clean      Analytics\n",
        "```\n",
        "\n",
        "### Benefits:\n",
        "- **Incremental Refinement**: Each layer adds value\n",
        "- **Data Quality**: Progressive validation and cleansing\n",
        "- **Performance**: Optimized for different use cases\n",
        "- **Flexibility**: Easy to add new sources or metrics\n",
        "\n",
        "### Real-World Use Cases:\n",
        "- **Finance**: Transaction processing and fraud detection\n",
        "- **E-commerce**: Customer analytics and product performance\n",
        "- **Healthcare**: Patient records and clinical analytics\n",
        "- **IoT**: Sensor data processing and anomaly detection\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup & Configuration\n",
        "\n",
        "First, let's set up our environment and create database schemas for each layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "from delta.tables import DeltaTable\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "print(f\"Spark version: {spark.version}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Create databases/schemas for each layer\n",
        "-- \n",
        "-- FOR COMMUNITY EDITION (Free): Uses Hive metastore\n",
        "-- FOR PAID WORKSPACES with Unity Catalog: Change to CREATE SCHEMA\n",
        "--   Example: CREATE SCHEMA IF NOT EXISTS main.bronze\n",
        "\n",
        "CREATE DATABASE IF NOT EXISTS bronze\n",
        "COMMENT 'Raw data layer - ingested as-is from source systems';\n",
        "\n",
        "CREATE DATABASE IF NOT EXISTS silver\n",
        "COMMENT 'Cleaned and validated data layer';\n",
        "\n",
        "CREATE DATABASE IF NOT EXISTS gold\n",
        "COMMENT 'Business-ready analytics layer';\n",
        "\n",
        "SHOW DATABASES;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration - CSV Data Location\n",
        "# The notebook will automatically detect if running from Git Repos\n",
        "# If not, it will look for CSVs in the path below\n",
        "\n",
        "# Default path for manually uploaded CSVs\n",
        "DATA_PATH = \"/FileStore/tables\"\n",
        "\n",
        "# Alternative paths (uncomment if needed):\n",
        "# DATA_PATH = \"/Volumes/catalog/schema/volume\"  # Unity Catalog Volume\n",
        "# DATA_PATH = \"dbfs:/mnt/data\"                  # Mounted storage\n",
        "\n",
        "print(f\"Default data path: {DATA_PATH}\")\n",
        "print(\"(Auto-detection will check for Git Repos first)\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ Auto-Detect: Git Repo vs Manual Upload\n",
        "\n",
        "Run this cell to automatically detect your data source and create Bronze tables:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AUTO-DETECT & LOAD DATA\n",
        "import os\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"BRONZE LAYER: DATA INGESTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Try to detect data source\n",
        "current_path = os.getcwd()\n",
        "data_source = None\n",
        "csv_path = None\n",
        "\n",
        "# Option 1: Check if running from Git Repos\n",
        "if \"/Workspace/Repos/\" in current_path:\n",
        "    repo_data_path = f\"{current_path}/data\"\n",
        "    try:\n",
        "        # Try to access files in repo\n",
        "        dbutils.fs.ls(f\"file://{repo_data_path}\")\n",
        "        data_source = \"git_repo\"\n",
        "        csv_path = f\"file://{repo_data_path}\"\n",
        "        print(f\"\\nüéØ GIT REPO DETECTED\")\n",
        "        print(f\"   Loading CSVs from: {repo_data_path}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# Option 2: Use configured DATA_PATH (manual upload)\n",
        "if not data_source:\n",
        "    try:\n",
        "        files = dbutils.fs.ls(DATA_PATH)\n",
        "        csv_files = [f for f in files if f.name.endswith('.csv')]\n",
        "        if csv_files:\n",
        "            data_source = \"manual_upload\"\n",
        "            csv_path = DATA_PATH\n",
        "            print(f\"\\nüì§ MANUAL UPLOAD DETECTED\")\n",
        "            print(f\"   Loading CSVs from: {DATA_PATH}\")\n",
        "            print(f\"   Found {len(csv_files)} CSV files\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ö†Ô∏è  ERROR: Could not find CSV files!\")\n",
        "        print(f\"   Tried: {DATA_PATH}\")\n",
        "        print(f\"\\nüí° To upload CSV files:\")\n",
        "        print(f\"   1. Data ‚Üí Create Table ‚Üí Upload File\")\n",
        "        print(f\"   2. Upload: customers.csv, products.csv, orders.csv, order_items.csv\")\n",
        "        print(f\"   3. Update DATA_PATH variable above if needed\")\n",
        "        raise Exception(\"No data source found\")\n",
        "\n",
        "print(f\"\\nüìã Creating Bronze tables with PySpark...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Define tables to create\n",
        "tables = {\n",
        "    \"customers\": \"bronze.customers\",\n",
        "    \"products\": \"bronze.products\", \n",
        "    \"orders\": \"bronze.orders\",\n",
        "    \"order_items\": \"bronze.order_items\"\n",
        "}\n",
        "\n",
        "# Load each CSV and create Bronze table\n",
        "for csv_name, table_name in tables.items():\n",
        "    print(f\"\\n‚è≥ Processing {csv_name}.csv...\")\n",
        "    \n",
        "    # Read CSV\n",
        "    csv_file = f\"{csv_path}/{csv_name}.csv\"\n",
        "    df = spark.read.csv(csv_file, header=True, inferSchema=True)\n",
        "    \n",
        "    # Add metadata columns\n",
        "    df = df.withColumn(\"_ingestion_timestamp\", current_timestamp()) \\\n",
        "           .withColumn(\"_source_file\", lit(f\"{csv_name}.csv\"))\n",
        "    \n",
        "    # Write to Bronze Delta table\n",
        "    df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(table_name)\n",
        "    \n",
        "    # Verify\n",
        "    count = spark.table(table_name).count()\n",
        "    print(f\"   ‚úÖ {table_name}: {count:,} records\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéâ BRONZE LAYER COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nAll CSV data has been loaded into Delta tables.\")\n",
        "print(\"You can now proceed to the Silver layer below.\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# ü•â Bronze Layer: Verify & Explore\n",
        "\n",
        "The Bronze tables have been created above! Let's verify and explore the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verify Bronze Tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Show all Bronze tables\n",
        "SHOW TABLES IN bronze;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Check record counts\n",
        "SELECT 'customers' as table_name, COUNT(*) as record_count FROM bronze.customers\n",
        "UNION ALL\n",
        "SELECT 'products', COUNT(*) FROM bronze.products\n",
        "UNION ALL\n",
        "SELECT 'orders', COUNT(*) FROM bronze.orders\n",
        "UNION ALL\n",
        "SELECT 'order_items', COUNT(*) FROM bronze.order_items;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Preview customers data\n",
        "SELECT * FROM bronze.customers LIMIT 5;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preview Other Tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Preview products\n",
        "SELECT * FROM bronze.products LIMIT 5;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Quality Check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Check for any null key columns (should be none)\n",
        "SELECT\n",
        "  'customers' as table_name,\n",
        "  SUM(CASE WHEN customer_id IS NULL THEN 1 ELSE 0 END) as null_ids\n",
        "FROM bronze.customers\n",
        "UNION ALL\n",
        "SELECT \n",
        "  'products',\n",
        "  SUM(CASE WHEN product_id IS NULL THEN 1 ELSE 0 END)\n",
        "FROM bronze.products\n",
        "UNION ALL\n",
        "SELECT \n",
        "  'orders',\n",
        "  SUM(CASE WHEN order_id IS NULL THEN 1 ELSE 0 END)\n",
        "FROM bronze.orders\n",
        "UNION ALL\n",
        "SELECT \n",
        "  'order_items',\n",
        "  SUM(CASE WHEN line_item_id IS NULL THEN 1 ELSE 0 END)\n",
        "FROM bronze.order_items;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úÖ Bronze Layer Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Summary statistics\n",
        "print(\"=\"*70)\n",
        "print(\"BRONZE LAYER SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nCustomers:    {spark.table('bronze.customers').count():>10,} records\")\n",
        "print(f\"Products:     {spark.table('bronze.products').count():>10,} records\")\n",
        "print(f\"Orders:       {spark.table('bronze.orders').count():>10,} records\")\n",
        "print(f\"Order Items:  {spark.table('bronze.order_items').count():>10,} records\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ Bronze Layer Complete - Raw data loaded into Delta tables\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nKey Features:\")\n",
        "print(\"  ‚Ä¢ All data stored in Delta Lake format (ACID compliant)\")\n",
        "print(\"  ‚Ä¢ Metadata columns added (_ingestion_timestamp, _source_file)\")\n",
        "print(\"  ‚Ä¢ Ready for cleansing in Silver layer\")\n",
        "print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# ü•à Silver Layer: Data Cleansing & Validation\n",
        "\n",
        "## Goals:\n",
        "- **Clean**: Remove nulls, fix data types, standardize formats\n",
        "- **Validate**: Apply business rules and constraints\n",
        "- **Deduplicate**: Keep only unique, valid records\n",
        "- **Enrich**: Add derived columns for downstream use\n",
        "\n",
        "## Key Patterns:\n",
        "- Data quality checks\n",
        "- Deduplication using window functions\n",
        "- Type casting and formatting\n",
        "- Business rule validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Silver: Customers (Cleaned)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Create Silver customers with data quality rules\n",
        "DROP TABLE IF EXISTS silver.customers;\n",
        "\n",
        "CREATE TABLE silver.customers USING DELTA AS\n",
        "SELECT \n",
        "  customer_id,\n",
        "  INITCAP(TRIM(first_name)) as first_name,  -- Standardize casing\n",
        "  INITCAP(TRIM(last_name)) as last_name,\n",
        "  LOWER(TRIM(email)) as email,              -- Lowercase emails\n",
        "  phone,\n",
        "  address,\n",
        "  city,\n",
        "  UPPER(state) as state,                    -- Uppercase state codes\n",
        "  zip_code,\n",
        "  country,\n",
        "  registration_date,\n",
        "  customer_segment,\n",
        "  CURRENT_TIMESTAMP() as updated_at\n",
        "FROM bronze.customers\n",
        "WHERE \n",
        "  customer_id IS NOT NULL                   -- Must have ID\n",
        "  AND email IS NOT NULL                     -- Must have email\n",
        "  AND email LIKE '%@%'                      -- Valid email format\n",
        "  AND registration_date IS NOT NULL;        -- Must have registration date\n",
        "\n",
        "SELECT COUNT(*) as cleaned_count FROM silver.customers;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Compare Bronze vs Silver\n",
        "SELECT \n",
        "  'Bronze' as layer,\n",
        "  COUNT(*) as record_count\n",
        "FROM bronze.customers\n",
        "UNION ALL\n",
        "SELECT \n",
        "  'Silver' as layer,\n",
        "  COUNT(*) as record_count\n",
        "FROM silver.customers;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Silver: Products (Cleaned)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "DROP TABLE IF EXISTS silver.products;\n",
        "\n",
        "CREATE TABLE silver.products USING DELTA AS\n",
        "SELECT \n",
        "  product_id,\n",
        "  TRIM(product_name) as product_name,\n",
        "  category,\n",
        "  brand,\n",
        "  price,\n",
        "  stock_quantity,\n",
        "  is_active,\n",
        "  -- Add derived columns\n",
        "  CASE \n",
        "    WHEN price < 50 THEN 'Budget'\n",
        "    WHEN price < 200 THEN 'Mid-Range'\n",
        "    ELSE 'Premium'\n",
        "  END as price_tier,\n",
        "  CURRENT_TIMESTAMP() as updated_at\n",
        "FROM bronze.products\n",
        "WHERE \n",
        "  product_id IS NOT NULL\n",
        "  AND product_name IS NOT NULL\n",
        "  AND price > 0                           -- Price must be positive\n",
        "  AND price < 10000;                      -- Sanity check on max price\n",
        "\n",
        "SELECT COUNT(*) as cleaned_count FROM silver.products;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Silver: Orders (Cleaned & Enriched)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "DROP TABLE IF EXISTS silver.orders;\n",
        "\n",
        "CREATE TABLE silver.orders USING DELTA AS\n",
        "SELECT \n",
        "  order_id,\n",
        "  customer_id,\n",
        "  order_date,\n",
        "  status,\n",
        "  payment_method,\n",
        "  shipped_date,\n",
        "  delivered_date,\n",
        "  discount_percent,\n",
        "  -- Calculate fulfillment time\n",
        "  CASE \n",
        "    WHEN delivered_date IS NOT NULL \n",
        "    THEN DATEDIFF(delivered_date, DATE(order_date))\n",
        "    ELSE NULL\n",
        "  END as days_to_deliver,\n",
        "  -- Extract time dimensions\n",
        "  YEAR(order_date) as order_year,\n",
        "  MONTH(order_date) as order_month,\n",
        "  DAYOFWEEK(order_date) as order_day_of_week,\n",
        "  CURRENT_TIMESTAMP() as updated_at\n",
        "FROM bronze.orders\n",
        "WHERE \n",
        "  order_id IS NOT NULL\n",
        "  AND customer_id IS NOT NULL\n",
        "  AND order_date IS NOT NULL\n",
        "  AND status IN ('Completed', 'Shipped', 'Processing', 'Cancelled');  -- Valid statuses only\n",
        "\n",
        "SELECT COUNT(*) as cleaned_count FROM silver.orders;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Silver: Order Items (Cleaned with Calculations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "DROP TABLE IF EXISTS silver.order_items;\n",
        "\n",
        "CREATE TABLE silver.order_items USING DELTA AS\n",
        "SELECT \n",
        "  line_item_id,\n",
        "  order_id,\n",
        "  product_id,\n",
        "  quantity,\n",
        "  unit_price,\n",
        "  -- Calculate line total\n",
        "  quantity * unit_price as line_total,\n",
        "  CURRENT_TIMESTAMP() as updated_at\n",
        "FROM bronze.order_items\n",
        "WHERE \n",
        "  line_item_id IS NOT NULL\n",
        "  AND order_id IS NOT NULL\n",
        "  AND product_id IS NOT NULL\n",
        "  AND quantity > 0                        -- Positive quantity\n",
        "  AND quantity <= 100                     -- Sanity check\n",
        "  AND unit_price > 0                      -- Positive price\n",
        "  AND unit_price < 10000;                 -- Sanity check\n",
        "\n",
        "SELECT COUNT(*) as cleaned_count FROM silver.order_items;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úÖ Silver Layer Complete!\n",
        "\n",
        "Summary of our cleansed data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare Bronze vs Silver record counts\n",
        "print(\"=\"*70)\n",
        "print(\"BRONZE ‚Üí SILVER DATA QUALITY REPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "tables = ['customers', 'products', 'orders', 'order_items']\n",
        "for table in tables:\n",
        "    bronze_count = spark.table(f'bronze.{table}').count()\n",
        "    silver_count = spark.table(f'silver.{table}').count()\n",
        "    rejected = bronze_count - silver_count\n",
        "    rejection_rate = (rejected / bronze_count * 100) if bronze_count > 0 else 0\n",
        "    \n",
        "    print(f\"\\n{table.upper()}:\")\n",
        "    print(f\"  Bronze: {bronze_count:>10,}\")\n",
        "    print(f\"  Silver: {silver_count:>10,}\")\n",
        "    print(f\"  Rejected: {rejected:>8,} ({rejection_rate:.2f}%)\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# ü•á Gold Layer: Business Analytics\n",
        "\n",
        "## Goals:\n",
        "- Create **business-ready** tables optimized for reporting\n",
        "- Pre-calculate **metrics and KPIs**\n",
        "- Denormalize data for **fast queries**\n",
        "- Support **dashboards and analytics**\n",
        "\n",
        "## Patterns:\n",
        "- Aggregations and rollups\n",
        "- Star schema / dimensional modeling\n",
        "- Pre-calculated metrics\n",
        "- Optimized for BI tools\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gold: Customer Analytics\n",
        "\n",
        "Calculate customer lifetime value and segmentation metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "DROP TABLE IF EXISTS gold.customer_analytics;\n",
        "\n",
        "CREATE TABLE gold.customer_analytics USING DELTA AS\n",
        "WITH order_totals AS (\n",
        "  SELECT \n",
        "    o.customer_id,\n",
        "    o.order_id,\n",
        "    SUM(oi.line_total) as order_total\n",
        "  FROM silver.orders o\n",
        "  INNER JOIN silver.order_items oi ON o.order_id = oi.order_id\n",
        "  WHERE o.status != 'Cancelled'\n",
        "  GROUP BY o.customer_id, o.order_id\n",
        ")\n",
        "SELECT \n",
        "  c.customer_id,\n",
        "  c.first_name,\n",
        "  c.last_name,\n",
        "  c.email,\n",
        "  c.city,\n",
        "  c.state,\n",
        "  c.customer_segment,\n",
        "  c.registration_date,\n",
        "  -- Order metrics\n",
        "  COUNT(DISTINCT o.order_id) as total_orders,\n",
        "  COALESCE(SUM(ot.order_total), 0) as lifetime_value,\n",
        "  COALESCE(AVG(ot.order_total), 0) as avg_order_value,\n",
        "  MAX(o.order_date) as last_order_date,\n",
        "  MIN(o.order_date) as first_order_date,\n",
        "  DATEDIFF(MAX(o.order_date), MIN(o.order_date)) as customer_tenure_days,\n",
        "  -- Engagement score (orders per month as customer)\n",
        "  CASE \n",
        "    WHEN DATEDIFF(MAX(o.order_date), MIN(o.order_date)) > 0 \n",
        "    THEN COUNT(DISTINCT o.order_id) * 30.0 / DATEDIFF(MAX(o.order_date), MIN(o.order_date))\n",
        "    ELSE 0\n",
        "  END as orders_per_month,\n",
        "  CURRENT_TIMESTAMP() as calculated_at\n",
        "FROM silver.customers c\n",
        "LEFT JOIN silver.orders o ON c.customer_id = o.customer_id AND o.status != 'Cancelled'\n",
        "LEFT JOIN order_totals ot ON o.order_id = ot.order_id\n",
        "GROUP BY \n",
        "  c.customer_id, c.first_name, c.last_name, c.email, \n",
        "  c.city, c.state, c.customer_segment, c.registration_date;\n",
        "\n",
        "SELECT COUNT(*) as customer_count FROM gold.customer_analytics;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Top 10 customers by lifetime value\n",
        "SELECT \n",
        "  customer_id,\n",
        "  first_name || ' ' || last_name as customer_name,\n",
        "  email,\n",
        "  total_orders,\n",
        "  ROUND(lifetime_value, 2) as lifetime_value,\n",
        "  ROUND(avg_order_value, 2) as avg_order_value,\n",
        "  customer_segment\n",
        "FROM gold.customer_analytics\n",
        "ORDER BY lifetime_value DESC\n",
        "LIMIT 10;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gold: Product Performance\n",
        "\n",
        "Analyze product sales and revenue.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "DROP TABLE IF EXISTS gold.product_performance;\n",
        "\n",
        "CREATE TABLE gold.product_performance USING DELTA AS\n",
        "SELECT \n",
        "  p.product_id,\n",
        "  p.product_name,\n",
        "  p.category,\n",
        "  p.brand,\n",
        "  p.price,\n",
        "  p.price_tier,\n",
        "  -- Sales metrics\n",
        "  COUNT(DISTINCT oi.order_id) as orders_containing_product,\n",
        "  SUM(oi.quantity) as total_quantity_sold,\n",
        "  SUM(oi.line_total) as total_revenue,\n",
        "  AVG(oi.unit_price) as avg_selling_price,\n",
        "  -- Rankings\n",
        "  RANK() OVER (PARTITION BY p.category ORDER BY SUM(oi.line_total) DESC) as revenue_rank_in_category,\n",
        "  CURRENT_TIMESTAMP() as calculated_at\n",
        "FROM silver.products p\n",
        "LEFT JOIN silver.order_items oi ON p.product_id = oi.product_id\n",
        "LEFT JOIN silver.orders o ON oi.order_id = o.order_id AND o.status != 'Cancelled'\n",
        "GROUP BY \n",
        "  p.product_id, p.product_name, p.category, p.brand, p.price, p.price_tier;\n",
        "\n",
        "SELECT COUNT(*) as product_count FROM gold.product_performance;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Top 10 products by revenue\n",
        "SELECT \n",
        "  product_name,\n",
        "  category,\n",
        "  brand,\n",
        "  ROUND(total_revenue, 2) as total_revenue,\n",
        "  total_quantity_sold,\n",
        "  orders_containing_product,\n",
        "  revenue_rank_in_category\n",
        "FROM gold.product_performance\n",
        "ORDER BY total_revenue DESC\n",
        "LIMIT 10;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gold: Monthly Revenue Trends\n",
        "\n",
        "Time-series analysis for business reporting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "DROP TABLE IF EXISTS gold.monthly_revenue;\n",
        "\n",
        "CREATE TABLE gold.monthly_revenue USING DELTA AS\n",
        "WITH order_revenues AS (\n",
        "  SELECT \n",
        "    o.order_id,\n",
        "    o.order_date,\n",
        "    o.order_year,\n",
        "    o.order_month,\n",
        "    o.status,\n",
        "    SUM(oi.line_total) as order_total,\n",
        "    SUM(oi.line_total * o.discount_percent / 100) as discount_amount\n",
        "  FROM silver.orders o\n",
        "  INNER JOIN silver.order_items oi ON o.order_id = oi.order_id\n",
        "  WHERE o.status != 'Cancelled'\n",
        "  GROUP BY o.order_id, o.order_date, o.order_year, o.order_month, o.status\n",
        ")\n",
        "SELECT \n",
        "  order_year,\n",
        "  order_month,\n",
        "  DATE_TRUNC('month', order_date) as month_start_date,\n",
        "  COUNT(DISTINCT order_id) as total_orders,\n",
        "  SUM(order_total) as gross_revenue,\n",
        "  SUM(discount_amount) as total_discounts,\n",
        "  SUM(order_total - discount_amount) as net_revenue,\n",
        "  AVG(order_total) as avg_order_value,\n",
        "  -- Month-over-month growth\n",
        "  LAG(SUM(order_total)) OVER (ORDER BY order_year, order_month) as prev_month_revenue,\n",
        "  ROUND(\n",
        "    (SUM(order_total) - LAG(SUM(order_total)) OVER (ORDER BY order_year, order_month)) \n",
        "    / LAG(SUM(order_total)) OVER (ORDER BY order_year, order_month) * 100, \n",
        "    2\n",
        "  ) as mom_growth_percent,\n",
        "  CURRENT_TIMESTAMP() as calculated_at\n",
        "FROM order_revenues\n",
        "GROUP BY order_year, order_month, DATE_TRUNC('month', order_date)\n",
        "ORDER BY order_year, order_month;\n",
        "\n",
        "SELECT COUNT(*) as month_count FROM gold.monthly_revenue;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- View monthly revenue trends\n",
        "SELECT \n",
        "  TO_DATE(month_start_date) as month,\n",
        "  total_orders,\n",
        "  ROUND(gross_revenue, 2) as gross_revenue,\n",
        "  ROUND(net_revenue, 2) as net_revenue,\n",
        "  ROUND(avg_order_value, 2) as avg_order_value,\n",
        "  mom_growth_percent\n",
        "FROM gold.monthly_revenue\n",
        "ORDER BY month DESC\n",
        "LIMIT 12;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gold: Category Performance\n",
        "\n",
        "Category-level analytics for merchandising decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "DROP TABLE IF EXISTS gold.category_performance;\n",
        "\n",
        "CREATE TABLE gold.category_performance USING DELTA AS\n",
        "SELECT \n",
        "  p.category,\n",
        "  COUNT(DISTINCT p.product_id) as total_products,\n",
        "  COUNT(DISTINCT oi.order_id) as total_orders,\n",
        "  SUM(oi.quantity) as total_units_sold,\n",
        "  SUM(oi.line_total) as total_revenue,\n",
        "  AVG(oi.line_total) as avg_transaction_value,\n",
        "  MIN(p.price) as min_price,\n",
        "  MAX(p.price) as max_price,\n",
        "  AVG(p.price) as avg_price,\n",
        "  CURRENT_TIMESTAMP() as calculated_at\n",
        "FROM silver.products p\n",
        "LEFT JOIN silver.order_items oi ON p.product_id = oi.product_id\n",
        "LEFT JOIN silver.orders o ON oi.order_id = o.order_id AND o.status != 'Cancelled'\n",
        "GROUP BY p.category;\n",
        "\n",
        "SELECT * FROM gold.category_performance ORDER BY total_revenue DESC;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úÖ Gold Layer Complete!\n",
        "\n",
        "Summary of all Gold tables:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "SHOW TABLES IN gold;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gold layer summary\n",
        "print(\"=\"*70)\n",
        "print(\"GOLD LAYER SUMMARY - BUSINESS ANALYTICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nCustomer Analytics:  {spark.table('gold.customer_analytics').count():>10,} customers\")\n",
        "print(f\"Product Performance: {spark.table('gold.product_performance').count():>10,} products\")\n",
        "print(f\"Monthly Revenue:     {spark.table('gold.monthly_revenue').count():>10,} months\")\n",
        "print(f\"Category Performance:{spark.table('gold.category_performance').count():>10,} categories\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üéì Advanced Concepts\n",
        "\n",
        "## Delta Lake Features You've Used\n",
        "\n",
        "Throughout this notebook, you've leveraged powerful Delta Lake capabilities:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Time Travel\n",
        "\n",
        "Query previous versions of your data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- View table history\n",
        "DESCRIBE HISTORY silver.customers LIMIT 5;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Query a previous version (if you've updated the table)\n",
        "-- SELECT * FROM silver.customers VERSION AS OF 0;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table Statistics & Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- View detailed table information\n",
        "DESCRIBE EXTENDED gold.customer_analytics;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Optimize tables for better query performance\n",
        "-- OPTIMIZE gold.customer_analytics;\n",
        "-- OPTIMIZE gold.product_performance;\n",
        "-- OPTIMIZE gold.monthly_revenue;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üéâ Congratulations!\n",
        "\n",
        "You've successfully built a complete **Medallion Architecture** on Databricks!\n",
        "\n",
        "## What You Accomplished:\n",
        "\n",
        "### ‚úÖ Bronze Layer\n",
        "- Ingested raw CSV data into Delta tables\n",
        "- Preserved complete data history\n",
        "- Used idempotent `COPY INTO` pattern\n",
        "\n",
        "### ‚úÖ Silver Layer\n",
        "- Cleaned and validated data\n",
        "- Applied business rules\n",
        "- Added derived columns\n",
        "- Standardized formats\n",
        "\n",
        "### ‚úÖ Gold Layer\n",
        "- Created business-ready analytics tables\n",
        "- Pre-calculated KPIs and metrics\n",
        "- Built customer lifetime value analysis\n",
        "- Analyzed product and category performance\n",
        "- Created time-series revenue trends\n",
        "\n",
        "## Key Concepts Mastered:\n",
        "\n",
        "- üì¶ **Delta Lake**: ACID transactions, time travel, schema evolution\n",
        "- üèóÔ∏è **Medallion Architecture**: Progressive data refinement\n",
        "- üîÑ **ETL Patterns**: Incremental loading, data quality, transformations\n",
        "- üìä **Analytics Engineering**: Business metrics, aggregations, rankings\n",
        "- üöÄ **Performance**: Optimizations, partitioning strategies\n",
        "\n",
        "## Next Steps:\n",
        "\n",
        "1. **Explore Further**: Try modifying queries to answer your own business questions\n",
        "2. **Add Complexity**: Implement slowly changing dimensions (SCD Type 2)\n",
        "3. **Automation**: Learn about Databricks Workflows to schedule these pipelines\n",
        "4. **Streaming**: Explore Structured Streaming for real-time data\n",
        "5. **ML Integration**: Build machine learning models on your clean data\n",
        "6. **Check Best Practices**: Review notebook 03 for advanced patterns\n",
        "\n",
        "---\n",
        "\n",
        "## Sample Business Questions You Can Answer:\n",
        "\n",
        "```sql\n",
        "-- Who are the most valuable customers?\n",
        "SELECT * FROM gold.customer_analytics \n",
        "ORDER BY lifetime_value DESC LIMIT 10;\n",
        "\n",
        "-- What products drive the most revenue?\n",
        "SELECT * FROM gold.product_performance \n",
        "ORDER BY total_revenue DESC LIMIT 10;\n",
        "\n",
        "-- How is revenue trending?\n",
        "SELECT * FROM gold.monthly_revenue \n",
        "ORDER BY order_year DESC, order_month DESC;\n",
        "\n",
        "-- Which categories perform best?\n",
        "SELECT * FROM gold.category_performance \n",
        "ORDER BY total_revenue DESC;\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**You're now ready to build production data pipelines on Databricks! üöÄ**\n",
        "\n",
        "Questions? Check out:\n",
        "- [Databricks Documentation](https://docs.databricks.com/)\n",
        "- [Delta Lake Guide](https://docs.delta.io/)\n",
        "- [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
